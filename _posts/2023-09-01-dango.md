---
title: The dango mental model of Vulkan sync
date: 2023-09-01 06:00:00 +/-0000
categories: [blog]
tags: [gpu, vulkan, tutorial]     # TAG names should always be lowercase
author: martty
toc: true
toc_sticky: true

---

# Intro

Many beginners struggle with Vulkan synchronization, and even experts get tripped every now-and-then by the various corner cases.
However, to get started, it is important to have a good mental model of what synchronization is for.
In this tutorial blogpost, I will present a mental model that may help to understand how execution and memory dependencies work in Vulkan.

# Of dangos and bears

To keep things less dry we will try to imagine the inner working of a GPU with sweets and animals.

![initial dango model](/assets/dango/initial_model.png){: w="400" h="400" }
_Initial mental model_

First, let's introduce some names for things in the model.

We will imagine that we have *queues* which are linear timelines with branches. We will concentrate on one of those queues for now.
The branches of the queue timeline correspond to draws, dispatches or other commands of the GPU, which execute over a number of *stages*. For posterity,
we will use 3 stages here - one for vertex work, one for fragment work and one for color framebuffer work (blending, storing color, etc.).
Furthermore, we can refer to the beginning of a branch as top-of-pipe (TOP) and the end as bottom-of-pipe (BOP). At each stage there is some work that the GPU has to do -
we will call these *work items* or, as we can clearly see, these are delicious dangos.

![dango](https://upload.wikimedia.org/wikipedia/commons/c/cf/Hanami_dango_by_gochie-_in_Seiryu-cho%2C_Kyoto.jpg){: w="400" h="400" }
_Dangos[^dango_attrib]!_

So what do we want to do with dangos? We want to eat them! So does our friend - the **Grand Prone Ursine** (GPU). We will use its stomach as a helpful aid
which we will call the *potential working set*.

![Grand Prone Ursine (GPU)](/assets/dango/gpu.png){: w="400" h="400" }
_(the bear is actually called Locutus)_

To keep the bear fed, we will send *feeders* down the queue timeline (blue arrows). Whenever a feeder encounters a branch, it will split and send one feeder down the branch.
When a feeder reaches BOP, it winks out of existence.

![full dango model](/assets/dango/full_model.png){: w="400" h="400" }
_Mental model with feeders_

# Ã€ Table

Now, let's see how this model works when we have independent work: the feeders go down the paths and for each work item (dango) they encounter, the dango is moved into the potential working set (the belly).

![independent workload](/assets/dango/independent.png){: w="400" h="400" }
_Nom nom nom_

This means that that particular work item corresponding to the stage is potentially worked on by the GPU.
We can see that the feeders don't progress through the work items at an equal rate, hence we can't predict in what order the feeders will add the items or when the items are finished being worked on.
This is what we mean by the *potential working set* - we can't know for certain whether the GPU has *actually* started all of the work or finished all of the work,
but we do know that there is a possibility that the GPU is currently working on it.

> Keep in mind that work items stay in the potential working set even when the feeder that encountered them finishes.
{: .prompt-info }

This forms the base of our understanding of the GPU work execution on a single queue: the GPU starts drawcalls in order, but they can finish out of order.
Each stage within a single drawcall can also finish out-of-order (remember that passing over a work item doesn't mean it is done). However, there is a guarantee that dependent work is correctly ordered - the GPU will not execute a fragment shader which depends on a vertex shader that has not yet been completed.

# It takes two to dango
We now ramp up the difficulty. We introduce a new draw (#5), but this time, we will have a logical depency between the vertex shader of this draw and the fragment shader of draw #4. This means that the fragment shader of draw #4 produces some effect that the vertex shader of draw #5 must observe.

![dependent workload](/assets/dango/dependent.png){: w="500" h="400" }

If we just let the dango machine operate, it will have both `5-VERTEX_SHADER` and `4-FRAGMENT_SHADER` in the potential working set (the belly) at the same time. This is called a hazard - we are unable to prove that the GPU can do this operation safely, as `5-VERTEX_SHADER` might start executing before `4-FRAGMENT_SHADER` ends.

This is when we need to introduce a dependency. For now, we will take care of ordering these two operations - we need `5-VERTEX_SHADER` to happen after `4-FRAGMENT_SHADER`.
We are going add in a barrier:

![barrier added](/assets/dango/barrier.png){: w="500" h="400" }

> You can think of barriers taking effect at top-of-pipe, although it doesn't actually execute at any stage.
{: .prompt-info }

To ensure we keep the dango eating civil, we set up a barrier that will tell each feeder that passes through it what the rules are. When a feeder crosses through, the barrier lists the stages which have dependencies (destination) and the stages which are dependended on (source). The source stages must complete before the destination stages are executed so that their effects are observable by the destination stages. We denote this by the change of the color of a feeder. We may have multiple such rules active at the same time.

![pre-stall](/assets/dango/pre-stall.png){: w="500" h="400" }

Here we have a feeder that encountered the barrier and thus it has been updated with the rule, while the feeders before the barrier carry on undisturbed.

![stall](/assets/dango/stall.png){: w="500" h="400" }

Our feeder on the right has now encountered a work item that it can't process as the rule has not yet been satisfied. It must now wait until the items from the FRAGMENT_SHADER before the barrier are actually done before it can continue.
We also see that the feeder on the main timeline continues unhindered.

![post-wait](/assets/dango/post-wait.png){: w="500" h="400" }
_For sure this analogy could be expanded here, but it won't be._

The wait has now completed - all the FRAGMENT_SHADER items are done. We retire these items from the potential working set as we now know that the GPU does not work on these. We also know that all of the VERTEX_SHADER items can be retired - as these are always before the FRAGMENT_SHADER items.
Our feeder after the barrier can now continue on and add `5-VERTEX_SHADER` to the potential working set without any issues.
Finally, as we have satisfied the rule, we can now remove it from the feeder.

The above is a good mental model to apply to figure out what *execution dependencies* are required: we are reasoning about the order of execution for work items. However, for correctness, we will need a second type of dependency: memory.

# Memory dependencies

# VK_EXT_dango

So we now know how dangos and bears work. Unfortunately, the concepts used within the Vulkan API are somewhat different, but the mental model still applies.

# Footnotes and glossary

[^dango_attrib]: Creative Commons Attribution 2.0 Generic License, [from](https://commons.wikimedia.org/wiki/File:Hanami_dango_by_gochie-_in_Seiryu-cho,_Kyoto.jpg)
